{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SNODAS Wrapper\n",
    "\n",
    "This code was written by Jonah Joughin with modifications by A. Arendt\n",
    "\n",
    "We're aware of a few other repos that overlap with this work:\n",
    "\n",
    "* David Hill's [matlab and shell scripts](https://github.com/dfosterhill/SNODAS)\n",
    "* David Shean's [Python snowtools](https://github.com/dshean/snowtools)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import re\n",
    "import os\n",
    "import math\n",
    "import xarray as xr\n",
    "import numpy as np\n",
    "import dask\n",
    "from datetime import datetime, timedelta\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from validation import SNODAS, MountainHub, Elevation, utils as ut"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Downloading Data from SNODAS\n",
    "Data can be fetched from SNODAS using the `snodas_ds(date)` function. It can then be saved using the appropriate function e.g. `save_netcdf(dataset, path)` or `save_tiff(dataset, path)`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fetch data from SNODAS\n",
    "start_date = datetime(2019,9,14)\n",
    "for date in (start_date + timedelta(n) for n in range(180)):\n",
    "    output_path = date.strftime('data/SNODAS/SNODAS_%Y%m%d.nc')\n",
    "    print(output_path)\n",
    "    if not os.path.exists(output_path):\n",
    "        snodas_ds = SNODAS.snodas_ds(date)\n",
    "        ut.save_netcdf(snodas_ds, output_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Merging files into single NetCDF files\n",
    "Merging together NetCDF files for different dates can be accomplished by reading those files into xarray, and then writing the resulting dataset out to a new NetCDF file. It is important to set the proper coordinates along the time axis of the dataset before writing, in order to record the date of each individual layer. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "output_path = 'data/SNODAS/SNODAS_2019_sample.nc'\n",
    "# Only process if file does not already exist\n",
    "if not os.path.exists(output_path):\n",
    "    # Get list of valid files\n",
    "    pattern = re.compile(\"^SNODAS_\\d{8}.nc$\")\n",
    "    # There's something wrong with SNODAS-20170913 - only use files after this for now\n",
    "    files = sorted([os.path.join(\"data/SNODAS\",f) for f in os.listdir(\"data/SNODAS\") if pattern.match(f)])\n",
    "    # Extract dates from files\n",
    "    dates = [ut.date_from_file(f) for f in files]\n",
    "\n",
    "    ds = xr.open_mfdataset(files, concat_dim='time', combine='nested')\n",
    "    ds.coords['time'] = dates\n",
    "    \n",
    "    ds.to_netcdf(output_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### MISSING MASKED FILES\n",
    "\n",
    "These notes are from David Hill's [shell script](https://github.com/dfosterhill/SNODAS/blob/master/get_proc_snodas.sh)\n",
    "\n",
    "### The following dates are missing ALL data (YYYY-MM-DD):\n",
    "\n",
    "* 2004-02-25\n",
    "* 2004-08-31\n",
    "* 2004-09-27\n",
    "* 2005-06-25\n",
    "* 2005-08-01\n",
    "* 2005-08-02\n",
    "* 2006-08-26\n",
    "* 2006-08-27\n",
    "* 2006-09-08\n",
    "* 2006-09-30\n",
    "* 2006-10-01\n",
    "* 2007-02-14\n",
    "* 2007-03-26\n",
    "* 2008-03-13\n",
    "* 2008-06-13\n",
    "* 2008-06-18\n",
    "* 2009-08-20\n",
    "* 2012-12-20\n",
    "\n",
    "### The following dates are missing individual files:\n",
    "\n",
    "2003-10-30 is missing one file:\n",
    "\n",
    "* us_ssmv11034tS__T0001TTNATS2003103005HP001"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loading Merged Data in XArray\n",
    "The merged dataset can then be reimported to xarray with the following function. The merging process is important, as it allows xarray to search the dataset much faster, opening up the possibility of API queries."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ds = xr.open_dataset('data/SNODAS/SNODAS_2017_2018.nc')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Selecting snow depth across region\n",
    "Data can be selected in a particular region by using the `sel` and `isel` functions in conjunction with `slice`, as shown below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ds.Band1.sel(time = '2017-12-31', lat = slice(40, 54), lon = slice(-126, -110)).plot()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Selecting time series at location\n",
    "A time series can be constructed as follows. It is important that the method parameter is set to `'nearest'` in order to recieve results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lat = 44.0018751\n",
    "lon = -122.004\n",
    "\n",
    "region = {\n",
    "    'ymax' : 44.25,\n",
    "    'ymin' : 43.75,\n",
    "    'xmax': -121.65,\n",
    "    'xmin': -122.5,\n",
    "}\n",
    "\n",
    "obs = MountainHub.snow_data(limit=1000, start=datetime(2017,8,1), end=datetime(2018,3,28), box=region)\n",
    "obs = Elevation.merge_el_data(obs)\n",
    "\n",
    "plot = obs.plot(x='date', y='snow_depth', style='o')\n",
    "snodas_series = ds.Band1.sel(lat=lat, lon=-122, method='nearest') / 10\n",
    "snodas_series.plot(ax=plot)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Selecting point data at time and location\n",
    "Data can be easily selected for a particular location and date. In the example below, snow depth is retrieved for January 3, 2018 near 44° N, 121.65° W."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ds.sel(time = '2018-1-3', lon = -121.65, lat = 44, method='nearest').Band1.item()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Plotting Data Against SNODAS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Restrict points to the continental US\n",
    "region = {\n",
    "    'ymax' : 50,\n",
    "    'ymin' : 25,\n",
    "    'xmax': -65,\n",
    "    'xmin': -125,\n",
    "}\n",
    "\n",
    "obs = MountainHub.snow_data(limit=1000, start=datetime(2017,9,14), end=datetime(2018,3,28), box=region)\n",
    "def snodas_depth(ts, lon, lat):\n",
    "    height = ds.Band1.sel(time = ts.strftime('%Y-%m-%d'), lon=lon, lat=lat, method='nearest').item()\n",
    "    if not np.isnan(height):\n",
    "        height /= 10\n",
    "    return height\n",
    "\n",
    "obs['snodas_depth'] = obs.apply(lambda x: snodas_depth(x['date'], x['long'], x['lat']), axis=1)\n",
    "\n",
    "sns.set(color_codes=True)\n",
    "sns.lmplot(x='snodas_depth',y='snow_depth',data=obs, fit_reg=True, lowess=True) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:CSO-validation]",
   "language": "python",
   "name": "conda-env-CSO-validation-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
